{
  "hash": "d23d3de9a270fa42af656c60d6f49feb",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Ingredients extraction\"\nexecute:\n  freeze: auto\ntitle-block-banner: \"#497D74\"\ndescription: Explore possibilities for ingredients extraction from a given input text.\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    number-sections: false\n    toc: true\n    toc-location: right\n    toc-depth: 2\n    toc-expand: 1\n    callout-icon: true\n    highlight-style: tango\n    code-line-numbers: ayu\n    embed-resources: true\n    theme: flatly\n    grid:\n        body-width: 1000px\n---\n\n## Context\n\nWe will add a feature to handle a recipe requests from the user by using natural language. \nThe request sentence will be parsed by a LLM to extract the ingredients that the user wants to include or exclude \nfrom the recipe. This list will then be used as input of the recipe recommendation system. The goal of this notebook \nis to explore the performance of LLMs for this task.\n\n## Test dataset\n\nWe will use a dataset containing 20 recipe requests. For each examples it contains:\n\n- A sentence in which the user ask for a recipe.\n- The list of ingredients that:\n  - The user likes\n  - The user doesn't like\n\nThis will be used as a benchmark. We will see if the model can accurately extract the ingredients from the sentence.\n\nHere is an example of recipe request and the corresponding expected ingredients:\n\n::: {#cell-2 .cell execution_count=1}\n``` {.python .cell-code}\nimport json\nfrom pathlib import Path\nfrom pprint import pprint\nfrom typing import Any\n\nimport pandas as pd\nfrom great_tables import GT\nfrom IPython.display import Image\nfrom IPython.display import display as idisplay\nfrom langchain_ollama import ChatOllama\nfrom langgraph.graph import END, START, StateGraph\nfrom openai import OpenAI\nfrom pydantic import BaseModel\nfrom typing_extensions import TypedDict\n\nTEST_FILE_PATH = Path.cwd().parent / \"data\" / \"test_cases_request_to_ingredients.json\"\n\n\nclass RecipeRequest(BaseModel):\n    \"\"\"A request for a recipe recommendation.\"\"\"\n\n    recipe_request: str\n    positive_ingredients: list[str]\n    negative_ingredients: list[str]\n\n\n# Load dataset\nwith Path.open(TEST_FILE_PATH, encoding=\"utf-8\") as json_file:\n    _test_recipes_requests_ingredients = json.load(json_file)\n\ntest_recipes_requests_ingredients = {k: RecipeRequest(**v) for k, v in _test_recipes_requests_ingredients.items()}\n\n# Display a sample\nfor i, k in enumerate(test_recipes_requests_ingredients.keys()):\n    if i >= 2:\n        break\n    print(test_recipes_requests_ingredients[k].model_dump_json(indent=2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{\n  \"recipe_request\": \"Suggest a dish for dinner. I'm fond of onions, bell peppers, and beef, but I'd rather avoid garlic.\",\n  \"positive_ingredients\": [\n    \"onions\",\n    \"bell peppers\",\n    \"beef\"\n  ],\n  \"negative_ingredients\": [\n    \"garlic\"\n  ]\n}\n{\n  \"recipe_request\": \"Could you recommend a recipe? I fancy potatoes, carrots, and peas.\",\n  \"positive_ingredients\": [\n    \"potatoes\",\n    \"carrots\",\n    \"peas\"\n  ],\n  \"negative_ingredients\": []\n}\n```\n:::\n:::\n\n\n## Benchmark\n\nIn order to easily compare models locally, we will use ollama and openai sdk to use different llms. \nOllama supports the structured output which allows to handle the LLM's output easily.\n\n::: {#cell-4 .cell execution_count=2}\n``` {.python .cell-code code-fold=\"false\"}\nclass Ingredients(BaseModel):\n    \"\"\"Lists of ingredients associated to positive and negative feelings\"\"\"\n\n    positive_ingredients: list[str]\n    negative_ingredients: list[str]\n\n\ndef get_ingredients(recipe_request: str, llm_credentials: dict, llm_model: str) -> Ingredients:\n    \"\"\"Get the list of positive and negative ingredients for a given recipe request.\"\"\"\n\n    client = OpenAI(**llm_credentials)\n\n    try:\n        completion = client.beta.chat.completions.parse(\n            temperature=0,\n            model=llm_model,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": (\n                        \"Provide the list of positive and negative ingredients for the following recipe \"\n                        f\"request in lowercase: {recipe_request}\"\n                    ),\n                }\n            ],\n            response_format=Ingredients,\n        )\n\n        recipe_response = completion.choices[0].message\n        if recipe_response.parsed:  # noqa: SIM108\n            ingredients = recipe_response.parsed\n        else:\n            ingredients = Ingredients(positive_ingredients=[], negative_ingredients=[])\n    except Exception as e:\n        print(e)\n        ingredients = Ingredients(positive_ingredients=[], negative_ingredients=[])\n\n    return ingredients\n```\n:::\n\n\n::: {#cell-5 .cell execution_count=3}\n``` {.python .cell-code}\ndef benchmark(\n    test_dataset: dict[str, RecipeRequest], llm_credentials: dict, llm_model: str\n) -> dict[str, dict[str, Any]]:\n    \"\"\"Test a list of ingredients with a given LLM.\"\"\"\n    benchmark_results = {}\n    for _id, req in test_dataset.items():\n        computed_result = get_ingredients(\n            recipe_request=req.recipe_request,\n            llm_credentials=llm_credentials,\n            llm_model=llm_model,\n        )\n        expected_result = Ingredients(\n            positive_ingredients=req.positive_ingredients, negative_ingredients=req.negative_ingredients\n        )\n\n        benchmark_results[_id] = {\n            \"recipe_request\": req.recipe_request,\n            \"computed_result\": computed_result,\n            \"expected_result\": expected_result,\n            \"correct_inference\": computed_result == expected_result,\n        }\n\n    return benchmark_results\n\n\ndef benchmark_overview(benchmark_results: dict[str, dict[str, Any]]) -> None:\n    \"\"\"Generate a table and a dataframe allowing to display the benchmark results.\"\"\"\n    NB_DISPLAYED_SAMPLES = 10\n\n    df_result = pd.DataFrame(benchmark_results).T\n    df_result[\"short_id\"] = df_result.index.str[:8]\n    table_result = (\n        GT(df_result.head(NB_DISPLAYED_SAMPLES), rowname_col=\"short_id\")\n        .tab_header(\n            title=\"Recipes ingredients extraction overview\",\n            subtitle=f\"Accuracy on full dataset: {df_result.correct_inference.mean():.1%}\",\n        )\n        .tab_source_note(source_note=f\"Only the first {NB_DISPLAYED_SAMPLES} cases are displayed.\")\n        .tab_options(\n            heading_background_color=\"#36665e\",\n            column_labels_background_color=\"#479487\",\n        )\n        .cols_label(recipe_request=\"Request\", computed_result=\"Computed ingredients\", correct_inference=\"Correct\")\n        .cols_hide(\"expected_result\")\n        .fmt(lambda x: \"✅\" if x else \"❌\", columns=[\"correct_inference\"])\n        .opt_align_table_header()\n        .cols_align(align=\"center\", columns=[\"recipe_request\", \"computed_result\"])\n        .opt_table_outline()\n    )\n\n    return df_result, table_result\n```\n:::\n\n\nLet's run the benchmark against a list of models.\n\n::: {#cell-7 .cell execution_count=4}\n``` {.python .cell-code code-fold=\"false\"}\nLLM_CREDENTIALS = {\"base_url\": \"http://localhost:11434/v1\", \"api_key\": \"ollama\"}\nAVAILABLE_MODELS = [\"smollm2:135m\", \"smollm2:360m\", \"llama3.2:1b\", \"gemma2:2b\", \"mistral:latest\"]\n\nmodels_result = {}\nfor model in AVAILABLE_MODELS:\n    benchmark_results = benchmark(\n        test_dataset=test_recipes_requests_ingredients,\n        llm_credentials=LLM_CREDENTIALS,\n        llm_model=model,\n    )\n    df_result, table_result = benchmark_overview(benchmark_results)\n\n    models_result[model] = (df_result, table_result)\n\n    print(f\"Model: {model:<15} | Accuracy: {df_result.correct_inference.mean():.1%}\")\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: smollm2:135m    | Accuracy: 30.0%\nModel: smollm2:360m    | Accuracy: 35.0%\nModel: llama3.2:1b     | Accuracy: 55.0%\nModel: gemma2:2b       | Accuracy: 100.0%\nModel: mistral:latest  | Accuracy: 100.0%\n```\n:::\n:::\n\n\nTwo models have a  100% accuracy: `gemma2:2b` and `mistral:latest` (7b). \nGemma2 is a smaller model than Mistral, and have a a good inference speed. \nWe will therefore use this model in the recipes inference app.\n\n\n_Remark: Using `mistral:latest` instead of a frozen version of a model (e.g. `mistral:v0.3`) can be seen as a bad \npractice as this could limit reproducibility. This is not a big issue here as we don't decide to use this model for \nthe app._\n\n::: {#cell-9 .cell execution_count=5}\n``` {.python .cell-code}\nUSED_MODEL = \"gemma2:2b\"\nmodels_result[USED_MODEL][1].tab_header(f\"[ {USED_MODEL} ] Recipes ingredients extraction overview\")\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div id=\"ywnwbxkdyn\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>\n#ywnwbxkdyn table {\n          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n          -webkit-font-smoothing: antialiased;\n          -moz-osx-font-smoothing: grayscale;\n        }\n\n#ywnwbxkdyn thead, tbody, tfoot, tr, td, th { border-style: none; }\n tr { background-color: transparent; }\n#ywnwbxkdyn p { margin: 0; padding: 0; }\n #ywnwbxkdyn .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 3px; border-top-color: #D3D3D3; border-right-style: solid; border-right-width: 3px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 3px; border-bottom-color: #D3D3D3; border-left-style: solid; border-left-width: 3px; border-left-color: #D3D3D3; }\n #ywnwbxkdyn .gt_caption { padding-top: 4px; padding-bottom: 4px; }\n #ywnwbxkdyn .gt_title { color: #FFFFFF; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }\n #ywnwbxkdyn .gt_subtitle { color: #FFFFFF; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }\n #ywnwbxkdyn .gt_heading { background-color: #36665e; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #ywnwbxkdyn .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #ywnwbxkdyn .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #ywnwbxkdyn .gt_col_heading { color: #FFFFFF; background-color: #479487; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }\n #ywnwbxkdyn .gt_column_spanner_outer { color: #FFFFFF; background-color: #479487; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }\n #ywnwbxkdyn .gt_column_spanner_outer:first-child { padding-left: 0; }\n #ywnwbxkdyn .gt_column_spanner_outer:last-child { padding-right: 0; }\n #ywnwbxkdyn .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }\n #ywnwbxkdyn .gt_spanner_row { border-bottom-style: hidden; }\n #ywnwbxkdyn .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }\n #ywnwbxkdyn .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }\n #ywnwbxkdyn .gt_from_md> :first-child { margin-top: 0; }\n #ywnwbxkdyn .gt_from_md> :last-child { margin-bottom: 0; }\n #ywnwbxkdyn .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }\n #ywnwbxkdyn .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }\n #ywnwbxkdyn .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }\n #ywnwbxkdyn .gt_row_group_first td { border-top-width: 2px; }\n #ywnwbxkdyn .gt_row_group_first th { border-top-width: 2px; }\n #ywnwbxkdyn .gt_striped { background-color: rgba(128,128,128,0.05); }\n #ywnwbxkdyn .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #ywnwbxkdyn .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }\n #ywnwbxkdyn .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }\n #ywnwbxkdyn .gt_left { text-align: left; }\n #ywnwbxkdyn .gt_center { text-align: center; }\n #ywnwbxkdyn .gt_right { text-align: right; font-variant-numeric: tabular-nums; }\n #ywnwbxkdyn .gt_font_normal { font-weight: normal; }\n #ywnwbxkdyn .gt_font_bold { font-weight: bold; }\n #ywnwbxkdyn .gt_font_italic { font-style: italic; }\n #ywnwbxkdyn .gt_super { font-size: 65%; }\n #ywnwbxkdyn .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }\n #ywnwbxkdyn .gt_asterisk { font-size: 100%; vertical-align: 0; }\n \n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n<thead>\n\n  <tr class=\"gt_heading\">\n    <td colspan=\"4\" class=\"gt_heading gt_title gt_font_normal\">[ gemma2:2b ] Recipes ingredients extraction overview</td>\n  </tr>\n<tr class=\"gt_col_headings\">\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"\"></th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Request\">Request</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Computed ingredients\">Computed ingredients</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Correct\">Correct</th>\n</tr>\n</thead>\n<tbody class=\"gt_table_body\">\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">29821f7b</th>\n    <td class=\"gt_row gt_center\">Suggest a dish for dinner. I'm fond of onions, bell peppers, and beef, but I'd rather avoid garlic.</td>\n    <td class=\"gt_row gt_center\">positive_ingredients=['onions', 'bell peppers', 'beef'] negative_ingredients=['garlic']</td>\n    <td class=\"gt_row gt_right\">✅</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">5ee092fb</th>\n    <td class=\"gt_row gt_center\">Could you recommend a recipe? I fancy potatoes, carrots, and peas.</td>\n    <td class=\"gt_row gt_center\">positive_ingredients=['potatoes', 'carrots', 'peas'] negative_ingredients=[]</td>\n    <td class=\"gt_row gt_right\">✅</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">2266ee45</th>\n    <td class=\"gt_row gt_center\">I'm seeking recipe ideas. I enjoy spinach, mushrooms, and cheese, but please exclude olives.</td>\n    <td class=\"gt_row gt_center\">positive_ingredients=['spinach', 'mushrooms', 'cheese'] negative_ingredients=['olives']</td>\n    <td class=\"gt_row gt_right\">✅</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">35a1b7b3</th>\n    <td class=\"gt_row gt_center\">What can I cook tonight? I'm a fan of eggs, milk, and flour, but I prefer not to include nuts.</td>\n    <td class=\"gt_row gt_center\">positive_ingredients=['eggs', 'milk', 'flour'] negative_ingredients=['nuts']</td>\n    <td class=\"gt_row gt_right\">✅</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">aec6722e</th>\n    <td class=\"gt_row gt_center\">I need inspiration for tonight's meal. I appreciate chicken, rice, and broccoli, but I'm not keen on food with spices like curry.</td>\n    <td class=\"gt_row gt_center\">positive_ingredients=['chicken', 'rice', 'broccoli'] negative_ingredients=['curry']</td>\n    <td class=\"gt_row gt_right\">✅</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">37f80099</th>\n    <td class=\"gt_row gt_center\">I'm in the mood for something new. I'm partial to pasta, tomatoes, and basil, but I'd prefer no meat in the recipe.</td>\n    <td class=\"gt_row gt_center\">positive_ingredients=['pasta', 'tomatoes', 'basil'] negative_ingredients=['meat']</td>\n    <td class=\"gt_row gt_right\">✅</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">70385f09</th>\n    <td class=\"gt_row gt_center\">I'm planning tonight's dinner. I'm interested in eggs, and flour, but I'd like to avoid nuts.</td>\n    <td class=\"gt_row gt_center\">positive_ingredients=['eggs', 'flour'] negative_ingredients=['nuts']</td>\n    <td class=\"gt_row gt_right\">✅</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">cc384148</th>\n    <td class=\"gt_row gt_center\">I'm brainstorming meal ideas. I'm inclined towards chicken, rice, and broccoli, but nothing too spicy.</td>\n    <td class=\"gt_row gt_center\">positive_ingredients=['chicken', 'rice', 'broccoli'] negative_ingredients=['spicy']</td>\n    <td class=\"gt_row gt_right\">✅</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">7d99cb39</th>\n    <td class=\"gt_row gt_center\">I'm exploring dinner options. I'm enthusiastic about spinach, mushrooms, and cheese, but let's leave out olives.</td>\n    <td class=\"gt_row gt_center\">positive_ingredients=['spinach', 'mushrooms', 'cheese'] negative_ingredients=['olives']</td>\n    <td class=\"gt_row gt_right\">✅</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">1a5bc0f4</th>\n    <td class=\"gt_row gt_center\">I'm considering what to cook. I'm drawn to potatoes, carrots, and peas, but I'd like to exclude onions.</td>\n    <td class=\"gt_row gt_center\">positive_ingredients=['potatoes', 'carrots', 'peas'] negative_ingredients=['onions']</td>\n    <td class=\"gt_row gt_right\">✅</td>\n  </tr>\n</tbody>\n  <tfoot class=\"gt_sourcenotes\">\n  \n  <tr>\n    <td class=\"gt_sourcenote\" colspan=\"4\">Only the first 10 cases are displayed.</td>\n  </tr>\n\n</tfoot>\n\n</table>\n\n</div>\n        \n```\n:::\n:::\n\n\n## Formatting\n\nThe ingredients are sometimes in plural form and sometimes in singular form. We need to standardize them to singular \nform to be consistent with the recipe database format. \nWe can take advantage of the versatility of the LLM to do this.\nAfter extracting the ingredients, we can ask the LLM to convert each item in singular form. \n\n\nTo implement this workflow, we can use the library `LangGraph` from the `LangChain` ecosystem.\n\n::: {#cell-11 .cell execution_count=6}\n``` {.python .cell-code}\nllm = ChatOllama(model=\"mistral:latest\", temperature=0)\n\n\nclass IngredientsSimpleList(BaseModel):\n    ingredients: list[str]\n\n\nclass State(TypedDict):\n    recipe_request: str\n    ingredients: Ingredients\n    positive_ingredients_singular: list[str]\n    negative_ingredients_singular: list[str]\n    ingredients_singular: Ingredients\n\n\n# Nodes\ndef extract_ingredients(state: State) -> dict[str, str]:\n    \"\"\"First LLM call to generate extract positive ingredients\"\"\"\n\n    msg = llm.with_structured_output(Ingredients).invoke(\n        \"Provide the list of positive and negative ingredients for the following recipe \"\n        f\"request in lowercase: {state['recipe_request']}\"\n    )\n    return {\"ingredients\": msg}\n\n\ndef make_positive_ingredients_singular(state: State) -> dict[str, list[str]]:\n    \"\"\"Second LLM call make positive ingredients singular\"\"\"\n\n    prompt = f\"\"\"\nTransform each item in the following list into its singular form.\nMake sure that no item is removed from the list.\nHere is the definition of the expected output: {IngredientsSimpleList.model_json_schema()}\n\nHere is the list: {state[\"ingredients\"].positive_ingredients}\"\"\"\n    msg = llm.with_structured_output(IngredientsSimpleList).invoke(prompt)\n    return {\"positive_ingredients_singular\": msg.ingredients}\n\n\ndef make_negative_ingredients_singular(state: State) -> dict[str, list[str]]:\n    \"\"\"Third LLM call make negative ingredients singular\"\"\"\n\n    prompt = f\"\"\"\nTransform each item in the following list into its singular form.\nMake sure that no item is removed from the list.\nHere is the definition of the expected output: {IngredientsSimpleList.model_json_schema()}\n\nHere is the list: {state[\"ingredients\"].negative_ingredients}\"\"\"\n    msg = llm.with_structured_output(IngredientsSimpleList).invoke(prompt)\n    return {\"negative_ingredients_singular\": msg.ingredients}\n\n\ndef make_ingredients_singular(state: State) -> dict[str, Ingredients]:\n    \"\"\"Gather previous results\"\"\"\n\n    ingredients_singular = Ingredients(\n        positive_ingredients=state[\"positive_ingredients_singular\"],\n        negative_ingredients=state[\"negative_ingredients_singular\"],\n    )\n    return {\"ingredients_singular\": ingredients_singular}\n\n\n# Build workflow\nworkflow = StateGraph(State)\n\n# Add nodes\nworkflow.add_node(\"extract_ingredients\", extract_ingredients)\nworkflow.add_node(\"make_positive_ingredients_singular\", make_positive_ingredients_singular)\nworkflow.add_node(\"make_negative_ingredients_singular\", make_negative_ingredients_singular)\nworkflow.add_node(\"make_ingredients_singular\", make_ingredients_singular)\n\n# Add edges to connect nodes\nworkflow.add_edge(START, \"extract_ingredients\")\nworkflow.add_edge(\"extract_ingredients\", \"make_positive_ingredients_singular\")\nworkflow.add_edge(\"extract_ingredients\", \"make_negative_ingredients_singular\")\nworkflow.add_edge(\"make_positive_ingredients_singular\", \"make_ingredients_singular\")\nworkflow.add_edge(\"make_negative_ingredients_singular\", \"make_ingredients_singular\")\nworkflow.add_edge(\"make_ingredients_singular\", END)\n\n# Compile\nchain = workflow.compile()\n```\n:::\n\n\nThe usage of library like `LangChain` comes with additionnal functionnalities, like the he ability to visualize the workflow.\n\n::: {#cell-13 .cell execution_count=7}\n``` {.python .cell-code}\n# Show workflow\nidisplay(Image(chain.get_graph().draw_mermaid_png()))\n```\n\n::: {.cell-output .cell-output-display}\n![](eda_ingredients_extraction_files/figure-html/cell-8-output-1.png){}\n:::\n:::\n\n\nIt also keeps track of every state of the workflow, which can be useful for debugging.\n\n::: {#cell-15 .cell execution_count=8}\n``` {.python .cell-code}\n# Invoke\nrecipe_request = \"What can I cook tonight? I'm a fan of eggs, milk, and flour, but I prefer not to include nuts.\"\nstate = chain.invoke({\"recipe_request\": recipe_request})\npprint(state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'ingredients': Ingredients(positive_ingredients=['eggs', 'milk', 'flour'], negative_ingredients=['nuts']),\n 'ingredients_singular': Ingredients(positive_ingredients=['egg', 'milk', 'flour'], negative_ingredients=['nut']),\n 'negative_ingredients_singular': ['nut'],\n 'positive_ingredients_singular': ['egg', 'milk', 'flour'],\n 'recipe_request': \"What can I cook tonight? I'm a fan of eggs, milk, and \"\n                   'flour, but I prefer not to include nuts.'}\n```\n:::\n:::\n\n\nWhile using this library can be beneficial, it introduces certain overheads. It adds an additional dependency to our project and increases complexity, potentially limiting compatibility and readability. For example, some models from `Ollama` are not compatible with structured outputs when accessed through the `LangChain` API.\n\n## Improvements\n\nThe current method struggles with imprecise ingredient descriptions. For example, if a user mentions disliking \"meat,\" this general term won't match specific entries like \"beef\" or \"chicken\" in the recipe database. Similarly, a preference against \"spicy food\" won't align with specific spicy ingredients. To address this, we could implement a semantic search to identify the closest matching ingredient in the database and substitute the original term.\n\n",
    "supporting": [
      "eda_ingredients_extraction_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}