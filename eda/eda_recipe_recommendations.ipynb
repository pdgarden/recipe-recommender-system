{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01dcf767",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Recipe recommendation system\"\n",
    "title-block-banner: \"#497D74\"\n",
    "description: Exploratory data analysis on recipe recommendation system leveraging word embeddings and similarities.\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-tools: true\n",
    "    number-sections: false\n",
    "    toc: true\n",
    "    toc-location: right\n",
    "    toc-depth: 2\n",
    "    toc-expand: 1\n",
    "    callout-icon: true\n",
    "    highlight-style: tango\n",
    "    code-line-numbers: ayu\n",
    "    embed-resources: true\n",
    "    theme: flatly\n",
    "    grid:\n",
    "        body-width: 1000px\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f713b",
   "metadata": {},
   "source": [
    "# Goal and context\n",
    "\n",
    "The aim of this study is to explore word embedding and similarities on recipes in order to create a content based recommender system.\n",
    "The dataset used is a sample of +6000 recipes extracted from the [recipeDB](https://cosylab.iiitd.edu.in/recipedb/).\n",
    "\n",
    "\n",
    "For each recipe, the name, ingredients and origin is provided. The recommender will suggest a list of recipes based on two user inputs:\n",
    "\n",
    "- A list of ingredients liked by the user.\n",
    "- A list of ingredients disliked by the user.\n",
    "\n",
    "*Inspired by Duarte Carmo's [work](https://duarteocarmo.com/blog/scandinavia-food-python-recommendation-systems)*\n",
    "\n",
    "\n",
    "## Import and check dataset\n",
    "\n",
    "We start by importing data and perform basic quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5619902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from great_tables import GT\n",
    "\n",
    "pio.templates.default = \"none\"\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "DATA_FOLDER = Path.cwd().parent / \"data\"\n",
    "SEED = 42\n",
    "\n",
    "df_recipes = pd.read_parquet(DATA_FOLDER / \"recipe_db_raw.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef189eb",
   "metadata": {},
   "source": [
    "The dataset is a table comprised of 4 columns:\n",
    "\n",
    "- **id:** the id of the recipe in the source database\n",
    "- **name:** the name of the recipe\n",
    "- **ingredients:** the list of ingredients used in the recipe, with a `|` as a separator\n",
    "- **origin:** the origin of the recipe, with different levels with a `>>` as a separator (e.g. `African >> Middle Eastern >> Egyptian`)\n",
    "\n",
    "We will perform a basic health check to make sure that the data doesn't contain unexpected things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da1455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = pd.concat(\n",
    "    [\n",
    "        df_recipes.dtypes.replace(\"object\", \"str\"),\n",
    "        df_recipes.notna().sum(),\n",
    "        df_recipes.isna().sum(),\n",
    "        (df_recipes == \"\").sum(),  # noqa: PLC1901\n",
    "        pd.concat([df_recipes[col].astype(str).str.len() for col in df_recipes.columns], axis=1).mean().round(1),\n",
    "        pd.concat([df_recipes[col].astype(str).str.len() for col in df_recipes.columns], axis=1).min(),\n",
    "        pd.concat([df_recipes[col].astype(str).str.len() for col in df_recipes.columns], axis=1).max(),\n",
    "    ],\n",
    "    axis=1,\n",
    ").reset_index()\n",
    "\n",
    "df_desc.columns = (\n",
    "    \"Column\",\n",
    "    \"Column type\",\n",
    "    \"# non null values\",\n",
    "    \"# None values\",\n",
    "    \"# value with empty string\",\n",
    "    \"# of characters (mean)\",\n",
    "    \"# of characters (min)\",\n",
    "    \"# of characters (max)\",\n",
    ")\n",
    "\n",
    "(\n",
    "    GT(df_desc, rowname_col=\"Column\")\n",
    "    .tab_header(\n",
    "        title=\"Recipes dataset overview\",\n",
    "    )\n",
    "    .tab_options(\n",
    "        column_labels_font_weight=\"bold\",\n",
    "        stub_font_weight=\"bold\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2a0e8c",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "- There are very few missing values in the column `ingredients` .\n",
    "- The columns data type are as expected\n",
    "- The repartition of string columns size is coherent\n",
    "\n",
    "--> The data doesn't seem to have obvious issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa45fb",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Some preprocessing must be done on the ingredients and origin columns in order to gain insight and remove / replace specific characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipes = df_recipes.dropna().reset_index(drop=True)\n",
    "\n",
    "df_recipes[\"origin\"] = df_recipes[\"origin\"].str.replace(\"\\n\", \"\").str.replace(\" \", \"\")\n",
    "\n",
    "df_recipes[\"origin_0\"] = df_recipes[\"origin\"].str.split(\">>\").apply(lambda origin_split: origin_split[0])\n",
    "df_recipes[\"origin_1\"] = df_recipes[\"origin\"].str.split(\">>\").apply(lambda origin_split: origin_split[1])\n",
    "df_recipes[\"origin_2\"] = df_recipes[\"origin\"].str.split(\">>\").apply(lambda origin_split: origin_split[2])\n",
    "\n",
    "df_recipes[\"ingredients_str\"] = df_recipes.ingredients.str.replace(\" | \", \", \", regex=False)\n",
    "\n",
    "df_recipes[\"origin\"] = df_recipes[\"origin\"].str.replace(\">>\", \" > \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97ca4f",
   "metadata": {},
   "source": [
    "## Preliminary EDA\n",
    "\n",
    "\n",
    "### Recipes origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51508ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    (df_recipes.origin_2.value_counts(ascending=True)).tail(35),\n",
    "    title=\"Nb of recipes per origin\",\n",
    "    orientation=\"h\",\n",
    "    height=700,\n",
    "    width=1100,\n",
    ").update_xaxes(title=\"Origin\").update_yaxes(title=\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd12d5a",
   "metadata": {},
   "source": [
    "Some recipes origin seems over-represented, we'll use the Lorentz curve to quantintify this more precisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_per_origin = df_recipes.origin_2.value_counts(ascending=True).rename(\"nb_recipes\").reset_index()\n",
    "\n",
    "recipes_per_origin[\"rank\"] = np.arange(len(recipes_per_origin)) + 1\n",
    "recipes_per_origin[\"cum_nb_recipes\"] = recipes_per_origin[\"nb_recipes\"].cumsum()\n",
    "\n",
    "recipes_per_origin[\"percent_rank\"] = recipes_per_origin[\"rank\"] / len(recipes_per_origin[\"rank\"])\n",
    "recipes_per_origin[\"percent_cum_nb_recipes\"] = (\n",
    "    recipes_per_origin[\"cum_nb_recipes\"].cumsum() / recipes_per_origin[\"cum_nb_recipes\"].sum()\n",
    ")\n",
    "\n",
    "recipes_per_origin[\"percent_rank\"] = (recipes_per_origin[\"percent_rank\"] * 100).round(2)\n",
    "recipes_per_origin[\"percent_cum_nb_recipes\"] = (recipes_per_origin[\"percent_cum_nb_recipes\"] * 100).round(2)\n",
    "\n",
    "px.scatter(\n",
    "    recipes_per_origin,\n",
    "    x=\"percent_rank\",\n",
    "    y=\"percent_cum_nb_recipes\",\n",
    "    hover_data=recipes_per_origin.columns,\n",
    "    title=\"Lorentz curve of # recipes per origin\",\n",
    "    width=1100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97018f1",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "The top 5% recipes origins gather almost 40% of recipes in the dataset.\n",
    "\n",
    "> The origin of recipes available in the dataset is unbalanced, this could lead to suggesting too much some kind of food. This could be taken into account in the recommender system . For example by adding an heuristic to filter out some regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794f8d8",
   "metadata": {},
   "source": [
    "### Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_per_recipe = df_recipes.ingredients.str.replace(\" | \", \"|\", regex=False).str.split(\"|\")\n",
    "full_ingredients = pd.Series([element for list_ in ingredients_per_recipe for element in list_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_INGREDIENTS_DISPLAY = 35\n",
    "\n",
    "ingredients_occurrence = (\n",
    "    full_ingredients.value_counts(ascending=True)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"ingredient\", 0: \"num_occurrences\"})\n",
    "    .assign(prop_occurences=lambda df: (df.num_occurrences / len(df_recipes) * 100))\n",
    "    .sort_values(\"num_occurrences\", ascending=True)\n",
    ")\n",
    "px.bar(\n",
    "    ingredients_occurrence.reset_index(drop=True).tail(35).round(1),\n",
    "    x=\"num_occurrences\",\n",
    "    y=\"ingredient\",\n",
    "    hover_data=ingredients_occurrence.columns,\n",
    "    title=f\"# ingredients occurrences in recipes (Top {NB_INGREDIENTS_DISPLAY} by occurence)\",\n",
    "    orientation=\"h\",\n",
    "    height=700,\n",
    "    width=1100,\n",
    "\n",
    ").update_xaxes(title=\"Ingredient\").update_yaxes(title=\"# occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab881d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ingredients_occurrence.iloc[[*np.arange(5), *(np.arange(-5, 0))]].reset_index(drop=True)\n",
    "\n",
    "(\n",
    "    GT(tmp, rowname_col=\"ingredient\")\n",
    "    .tab_header(\n",
    "        title=\"Top 5 and bottom 5 ingredients by occurrence\",\n",
    "    )\n",
    "    .fmt_percent(\n",
    "        \"prop_occurences\",\n",
    "        decimals=2,\n",
    "        scale_values=False,\n",
    "    )\n",
    "    # .fmt_nanoplot(columns=\"prop_occurences\", plot_type=\"bar\")\n",
    "    .data_color(\n",
    "        columns=[\n",
    "            \"prop_occurences\",\n",
    "            \"num_occurrences\",\n",
    "        ],\n",
    "        palette=\"RdBu\",\n",
    "        reverse=True,\n",
    "        alpha=0.5,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458bafee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"List of ingredients containing the word milk, by occurrence: \"\n",
    "    + \", \".join(\n",
    "        [\n",
    "            f\"{d['ingredient']} ({d['num_occurrences']})\"\n",
    "            for d in ingredients_occurrence[ingredients_occurrence.ingredient.str.contains(\"milk\")]\n",
    "            .iloc[::-1]\n",
    "            .to_dict(orient=\"records\")\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0a41e",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- The ingredients are very unbalanced, some ingredients are present in almost 40% of the recipes, while some are present in only one recipe.\n",
    "- The top 5 ingredients are basic and therefore not so discriminant.\n",
    "- Some people may not be tolerant to some of the most common ingredients (e.g. milk, ginger). This could be taken into account and be used as a filter.\n",
    "- We can see with the milk that some ingredients have a lot of declinations, where some are not real ingredients, e.g. cold / hot milk.\n",
    "\n",
    "\n",
    "\n",
    "Our approach based on vector embedding and similarity search should be able to group similar ingredients together. However the user might want only a specific ingredient and not the other (for instance, he might want oat milk but not rice milk). This might be a limitation to the solution, which could be mixed with hard filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ea22a",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n",
    "We will create an embedding model from the list of ingredients on each recipes. We will use a small embedding model \n",
    "which has a good ranking on the [MTEB leaderboard](https://huggingface.co/spaces/mteb/leaderboard) from HuggingFace. \n",
    "The embedding model is a source of improvement in our pipeline and we could test several model in a refining phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: false\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Import model\n",
    "EMBEDDING_MODEL = \"intfloat/multilingual-e5-small\"\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "\n",
    "\n",
    "# Create embeddings\n",
    "sentences_embeddings = model.encode(df_recipes.ingredients_str.to_list())\n",
    "embedding_matrix = sentences_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f59c05",
   "metadata": {},
   "source": [
    "## Embedding visualisation\n",
    "\n",
    "We reduce the embeddings' dimensionality with UMAP in order to get an overview of the embedding properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40cab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: false\n",
    "import umap\n",
    "\n",
    "# Reduce dimensionality\n",
    "umap_fit = umap.UMAP(random_state=SEED)\n",
    "umap_matrix = umap_fit.fit_transform(embedding_matrix)\n",
    "\n",
    "df_recipes[\"umap_comp_0\"] = umap_matrix[:, 0]\n",
    "df_recipes[\"umap_comp_1\"] = umap_matrix[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipes_subset = df_recipes.sample(5000, random_state=SEED).sort_values(\"id\")\n",
    "\n",
    "px.scatter(\n",
    "    df_recipes_subset,\n",
    "    x=\"umap_comp_0\",\n",
    "    y=\"umap_comp_1\",\n",
    "    color=\"origin_0\",\n",
    "    hover_data=[\"name\", \"ingredients\", \"origin\"],\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b28ba1c",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "We can see some clusters related to the recipe origin which is a good sign as a recipes from the same origin usually \n",
    "have similar ingredients and can be a strong signal for the taste.\n",
    "We will look more into detail for given dish in order as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipes_subset[\"is_pasta\"] = df_recipes.name.str.contains(\"pasta\", case=False)\n",
    "df_recipes_subset[\"is_pizza\"] = df_recipes.name.str.contains(\"pizza\", case=False)\n",
    "df_recipes_subset[\"is_salad\"] = df_recipes.name.str.contains(\"salad\", case=False)\n",
    "\n",
    "px.scatter(\n",
    "    df_recipes_subset,\n",
    "    x=\"umap_comp_0\",\n",
    "    y=\"umap_comp_1\",\n",
    "    color=\"is_pasta\",\n",
    "    hover_data=[\"name\", \"ingredients\", \"origin\"],\n",
    "    width=800,\n",
    "    height=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d008517",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "Pasta recipes are mostly clustered together, some deviations come from asian recipes which makes sense as it uses \n",
    "specific ingredients and tests.\n",
    "\n",
    "According to these sanity checks, the embeddings seem to be a good representation of the recipes. And we can therefore \n",
    "use similarity metrics on them in order create a recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302ae29",
   "metadata": {},
   "source": [
    "## Liked and disliked recipes visualisation\n",
    "\n",
    "We'll work on a semi-supervised method:\n",
    "\n",
    "1. Ask the affinity of the user with few ingredients.\n",
    "2. Use this information to label the recipes containing those ingredients\n",
    "3. Train a classification algorithm on those labelled recipes\n",
    "4. Use this algorithm to predict the affinity of the user with the rest of the recipes\n",
    "5. Use this information to recommend recipes\n",
    "\n",
    "\n",
    "Here is an example based on a list of liked and disliked ingredients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: false\n",
    "liked_ingredients = [\n",
    "    \"salt\",\n",
    "    \"onion\",\n",
    "    \"butter\",\n",
    "    \"olive oil\",\n",
    "    \"egg\",\n",
    "    \"soy sauce\",\n",
    "    \"vegetable oil\",\n",
    "    \"green onion\",\n",
    "    \"lemon juice\",\n",
    "    \"cream\",\n",
    "    \"lime juice\",\n",
    "    \"purpose flour\",\n",
    "    \"beef\",\n",
    "]\n",
    "\n",
    "\n",
    "disliked_ingredients = [\n",
    "    \"tomato\",\n",
    "    \"garlic\",\n",
    "    \"sugar\",\n",
    "    \"black pepper\",\n",
    "    \"cilantro\",\n",
    "    \"cumin\",\n",
    "    \"ginger\",\n",
    "    \"milk\",\n",
    "    \"cinnamon\",\n",
    "    \"pepper\",\n",
    "    \"salt pepper\",\n",
    "]\n",
    "\n",
    "df_recipes[\"liked\"] = 0\n",
    "\n",
    "for ingredient in liked_ingredients:\n",
    "    df_recipes[\"liked\"] += df_recipes[\"ingredients\"].str.contains(ingredient).astype(\"int\")\n",
    "\n",
    "for ingredient in disliked_ingredients:\n",
    "    df_recipes[\"liked\"] -= df_recipes[\"ingredients\"].str.contains(ingredient).astype(\"int\")\n",
    "\n",
    "\n",
    "df_recipes[\"liked_bool\"] = df_recipes[\"liked\"] / df_recipes[\"liked\"].abs().replace(0, 1)\n",
    "\n",
    "df_recipes[\"labeled\"] = df_recipes.liked_bool != 0\n",
    "\n",
    "df_recipes.liked_bool.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da73be",
   "metadata": {},
   "source": [
    "We can see a homogeneous distribution of liked and disliked values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8123b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    df_recipes,\n",
    "    x=\"umap_comp_0\",\n",
    "    y=\"umap_comp_1\",\n",
    "    color=\"liked\",\n",
    "    hover_data=[\"name\", \"ingredients_str\", \"origin\", \"liked\"],\n",
    "    color_continuous_scale=px.colors.diverging.RdBu_r,\n",
    "    title=\"Liked ingredients score\",\n",
    "    width=800,\n",
    "    height=800,\n",
    ").update_layout({\"plot_bgcolor\": \"#E0E0E0\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e64fb3",
   "metadata": {},
   "source": [
    "Some clusters seem to appear based on our list of liked and disliked ingredients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad10380",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "In order to label unlabelled data, we can define an affinity score based on the k-nearest-neighbors labels.\n",
    "The faiss library is used because of it's high computing efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: false\n",
    "import faiss\n",
    "\n",
    "NB_NEIGHBORS = 10\n",
    "\n",
    "# get label and unlabeled embeddings\n",
    "labeled_embeddings = embedding_matrix[df_recipes.labeled, :]\n",
    "unlabeled_embeddings = embedding_matrix[~df_recipes.labeled, :]\n",
    "\n",
    "\n",
    "# create faiss index\n",
    "vector_dimension = labeled_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(vector_dimension)\n",
    "\n",
    "\n",
    "# normalize and add labeled_embeddings\n",
    "faiss.normalize_L2(labeled_embeddings)\n",
    "index.add(labeled_embeddings)\n",
    "\n",
    "\n",
    "# normalize and query unlabeled_embeddings\n",
    "faiss.normalize_L2(unlabeled_embeddings)\n",
    "\n",
    "\n",
    "r_distances, r_indexes = index.search(unlabeled_embeddings, k=NB_NEIGHBORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e4a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: false\n",
    "\n",
    "df_labeled = df_recipes[df_recipes.liked_bool != 0].reset_index(drop=True)\n",
    "df_unlabeled = df_recipes[df_recipes.liked_bool == 0].reset_index(drop=True)\n",
    "\n",
    "neighbors_id_columns = [f\"neighbor_{i}_id\" for i in range(NB_NEIGHBORS)]\n",
    "neighbors_liked_columns = [f\"neighbor_{i}_liked_bool_value\" for i in range(NB_NEIGHBORS)]\n",
    "\n",
    "affinity = pd.DataFrame(r_indexes, index=df_unlabeled.id, columns=neighbors_id_columns)\n",
    "\n",
    "for i in range(NB_NEIGHBORS):\n",
    "    affinity[f\"neighbor_{i}_liked_bool_value\"] = affinity[f\"neighbor_{i}_id\"].map(df_labeled.liked_bool)\n",
    "\n",
    "\n",
    "affinity[\"liked_estimated_score\"] = affinity[neighbors_liked_columns].mean(axis=1)\n",
    "\n",
    "df_recipes[\"liked_estimated_score\"] = df_recipes[\"id\"].map(affinity.liked_estimated_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7845f9b",
   "metadata": {},
   "source": [
    "## Affinity visualisation\n",
    "\n",
    "### Affinity on embedding scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c164c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    df_recipes[~df_recipes.labeled],\n",
    "    x=\"umap_comp_0\",\n",
    "    y=\"umap_comp_1\",\n",
    "    color=\"liked_estimated_score\",\n",
    "    hover_data=[\"name\", \"ingredients_str\", \"origin\", \"liked\"],\n",
    "    color_continuous_scale=px.colors.diverging.RdBu_r,\n",
    "    title=\"Estimation of affinity score on recipes without label (i.e. without initial list of ingredients)\",\n",
    "    width=800,\n",
    "    height=800,\n",
    ").update_layout({\"plot_bgcolor\": \"#E0E0E0\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091bc1dd",
   "metadata": {},
   "source": [
    "### Sample of recipes with high estimated affinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pp\n",
    "\n",
    "for recipe in (\n",
    "    df_recipes[df_recipes.liked_estimated_score == 1][[\"name\", \"ingredients_str\"]]\n",
    "    .sample(5, random_state=SEED)\n",
    "    .to_dict(orient=\"records\")\n",
    "):\n",
    "    for _, v in recipe.items():\n",
    "        pp(v + \":\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7f4e7",
   "metadata": {},
   "source": [
    "Based on my tastes, the results seem very coherent. A more refined benchmark approach could be to define generate several pairs of liked, disliked ingredients along with a sample of recipes, rank them, and estimate if the recommender system is able to rank them in the he same order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee437a31",
   "metadata": {},
   "source": [
    "## Save data\n",
    "\n",
    "We save the embeddings to use them as is for fast inference in the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58dfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_recipes[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"name\",\n",
    "        \"origin_2\",\n",
    "        \"ingredients_str\",\n",
    "        \"umap_comp_0\",\n",
    "        \"umap_comp_1\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "df_embedding = pd.DataFrame(\n",
    "    embedding_matrix,\n",
    "    columns=[f\"embedding_feature_{i}\" for i in range(embedding_matrix.shape[1])],\n",
    ")\n",
    "\n",
    "df_features = df_features.join(df_embedding)\n",
    "df_features = df_features.dropna()\n",
    "df_features[\"name\"] = df_features[\"name\"].str.title()\n",
    "df_features[\"ingredients_str\"] = df_features[\"ingredients_str\"].str.title()\n",
    "\n",
    "df_features = df_features.rename(columns={\"name\": \"Name\", \"ingredients_str\": \"Ingredients\", \"origin_2\": \"Origin\"})\n",
    "df_features[\"Link\"] = \"https://cosylab.iiitd.edu.in/recipedb/search_recipeInfo/\" + df_features[\"id\"].astype(\"str\")\n",
    "\n",
    "df_features.sample().T.iloc[:10, :]\n",
    "\n",
    "df_features.to_parquet(DATA_FOLDER / \"recipe_db.parquet\", index=False)\n",
    "\n",
    "print(\"Processed dataset saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "188.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
